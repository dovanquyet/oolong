# Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities

A challenging aggregation benchmark for long-context models; full code and eval scripts release coming soon! See the [paper](https://arxiv.org/abs/2511.02817) for details


Release status:
- [ ] Output scoring scripts for both splits
- [ ] API inference script
- [ ] Oolong-synth construction code
- [ ] Validated splits of each Oolong-synth source dataset 
- [ ] Oolong-real construction code
- [ ] Full output sets for models from the paper
- [ ] Analysis scripts


## BibTeX
```
@misc{bertsch2025oolongevaluatinglongcontext,
      title={Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities}, 
      author={Amanda Bertsch and Adithya Pratapa and Teruko Mitamura and Graham Neubig and Matthew R. Gormley},
      year={2025},
      eprint={2511.02817},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2511.02817}, 
}
